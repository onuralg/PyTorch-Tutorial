{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial\n",
    "\n",
    "PyTorch is a Python library built on top of Torch’s THNN computational\n",
    "backend.\n",
    "\n",
    "Its main features are:\n",
    "\n",
    "- Efficient tensor operations on CPU/GPU,\n",
    "- automatic on-the-fly differentiation (autograd),\n",
    "- optimizers,\n",
    "- data I/O.\n",
    "\n",
    "“Efficient tensor operations” encompass both standard linear algebra and, as we will see later, deep-learning specific operations (convolution, pooling, etc.)\n",
    "\n",
    "A key specificity of PyTorch is the central role of autograd to compute\n",
    "derivatives of anything!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1 - Tensor Basics and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-4-tensors-and-linear-regression.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24b60aeb358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-4-tensors-and-linear-regression.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n",
      "2 - 5\n",
      "tensor([[1.1250, 1.1250, 1.1250, 1.1250, 1.1250],\n",
      "        [1.1250, 1.1250, 1.1250, 1.1250, 1.1250]])\n",
      "tensor(1.1250)\n",
      "tensor(0.)\n",
      "tensor(11.2500)\n",
      "11.25\n"
     ]
    }
   ],
   "source": [
    "# In-place operations are suffixed with an underscore, and a 0d tensor can be\n",
    "# converted back to a Python scalar with item().\n",
    "\n",
    "x = torch.empty(2, 5)\n",
    "print(x)\n",
    "\n",
    "print(x.size())\n",
    "print(str(x.size()[0]) + \" - \" + str(x.size()[1]))\n",
    "\n",
    "x.fill_(1.125)\n",
    "print(x)\n",
    "\n",
    "print(x.mean())\n",
    "print(x.std())\n",
    "print(x.sum())\n",
    "print(x.sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11., 12., 13.],\n",
      "        [21., 22., 23.]])\n",
      "tensor(23.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[11. , 12. ,13.], [21., 22., 23.]])\n",
    "\n",
    "print(x)\n",
    "print(x[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21., 41., 61.])\n",
      "tensor([110., 420., 930.])\n",
      "tensor([100., 400., 900.])\n",
      "tensor([90., 40., 10.])\n",
      "tensor([90., 40., 10.])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch provides operators for component-wise and vector/matrix operations.\n",
    "x = torch.tensor([10., 20., 30.])\n",
    "y = torch.tensor([11., 21., 31.])\n",
    "\n",
    "m = torch.tensor([[0., 0., 3.], [0., 2., 0.], [1., 0., 0.]])\n",
    "\n",
    "z1 = x + y\n",
    "z2 = x * y\n",
    "z3 = x**2\n",
    "\n",
    "z4 = m.mv(x)\n",
    "z5 = m @ x\n",
    "\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "print(z4)\n",
    "print(z5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 7., 1., 8.],\n",
      "        [3., 6., 3., 6.]])\n",
      "tensor([0., 7., 1., 8.])\n",
      "tensor([0., 7., 1., 8.])\n",
      "tensor([0., 3.])\n"
     ]
    }
   ],
   "source": [
    "# And as in numpy, the : symbol defines a range of values for an index and allows\n",
    "# to slice tensors.\n",
    "\n",
    "x = torch.empty(2, 4).random_(10)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x[0])\n",
    "print(x[0,:])\n",
    "\n",
    "print(x[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5098, -0.0341,  1.9124])\n",
      "tensor([[-0.3325,  0.1958, -0.6358],\n",
      "        [-0.3749, -0.4426,  0.4036],\n",
      "        [-0.1004, -0.5164, -0.6872]])\n",
      "tensor([[ 2.0517],\n",
      "        [-2.6535],\n",
      "        [-1.0884]])\n",
      "tensor([[-0.5098],\n",
      "        [-0.0341],\n",
      "        [ 1.9124]])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch provides interfacing to standard linear operations, such as linear system\n",
    "# solving or Eigen-decomposition.\n",
    "\n",
    "y = torch.empty(3).normal_()\n",
    "m = torch.empty(3, 3).normal_()\n",
    "print(y)\n",
    "print(m)\n",
    "\n",
    "q, _ = torch.lstsq(y,m)\n",
    "s = torch.mm(m,q)\n",
    "print(q)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2 - High Dimension Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-5-high-dimension-tensors.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24b60b04b38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-5-high-dimension-tensors.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor can be of several types:\n",
    "- torch.float16, torch.float32, torch.float64,\n",
    "- torch.uint8,\n",
    "- torch.int8, torch.int16, torch.int32, torch.int64\n",
    "\n",
    "and can be located either in the CPU’s or in a GPU’s memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu\n",
      "torch.int64 cpu\n",
      "torch.int64 cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1,3)\n",
    "print(x.dtype, x.device)\n",
    "\n",
    "x = x.long()\n",
    "print(x.dtype, x.device)\n",
    "\n",
    "x = x.to('cuda')\n",
    "print(x.dtype, x.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some examples from the vast library of tensor operations:\n",
    "#### Creation\n",
    "- torch.empty(*size, ...)\n",
    "- torch.zeros(*size, ...)\n",
    "- torch.full(size, value, ...)\n",
    "- torch.tensor(sequence, ...)\n",
    "- torch.eye(n, ...)\n",
    "- torch.from_numpy(ndarray)\n",
    "\n",
    "#### Indexing, Slicing, Joining, Mutating\n",
    "- torch.Tensor.view(*size)\n",
    "- torch.cat(inputs, dimension=0)\n",
    "- torch.chunk(tensor, nb_chunks, dim=0)[source]\n",
    "- torch.split(tensor, split_size, dim=0)[source]\n",
    "- torch.index_select(input, dim, index, out=None)\n",
    "- torch.t(input, out=None)\n",
    "- torch.transpose(input, dim0, dim1, out=None)\n",
    "\n",
    "#### Filling\n",
    "- Tensor.fill_(value)\n",
    "- torch.bernoulli_(proba)\n",
    "- torch.normal_([mu, [std]])\n",
    "\n",
    "#### Pointwise math\n",
    "- torch.abs(input, out=None)\n",
    "- torch.add()\n",
    "- torch.cos(input, out=None)\n",
    "- torch.sigmoid(input, out=None)\n",
    "- (+ many operators)\n",
    "\n",
    "#### Math reduction\n",
    "- torch.dist(input, other, p=2, out=None)\n",
    "- torch.mean()\n",
    "- torch.norm()\n",
    "- torch.std()\n",
    "- torch.sum()\n",
    "\n",
    "#### BLAS and LAPACK Operations\n",
    "- torch.eig(a, eigenvectors=False, out=None)\n",
    "- torch.lstsq(B, A, out=None)\n",
    "- torch.inverse(input, out=None)\n",
    "- torch.mm(mat1, mat2, out=None)\n",
    "- torch.mv(mat, vec, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 0],\n",
      "        [2, 4, 6]]) torch.Size([2, 3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [0, 6]]) torch.Size([3, 2])\n",
      "tensor([1, 3, 0, 2, 4, 6]) torch.Size([6])\n",
      "tensor([[1, 3],\n",
      "        [0, 2],\n",
      "        [4, 6]]) torch.Size([3, 2])\n",
      "tensor([[3, 0],\n",
      "        [4, 6]]) torch.Size([2, 2])\n",
      "tensor([[[1, 3, 0],\n",
      "         [2, 4, 6]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[1, 3, 0],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 0],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 0],\n",
      "         [2, 4, 6]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ [1, 3, 0], [2, 4, 6] ])\n",
    "\n",
    "x1 = x.t()\n",
    "x2 = x.view(-1)\n",
    "x3 = x.view(3, -1)\n",
    "x4 = x[:, 1:3]\n",
    "x5 = x.view(1, 2, 3)\n",
    "x6 = x.view(1, 2, 3).expand(3, 2, 3)\n",
    "\n",
    "print(x, x.size())\n",
    "print(x1, x1.size())\n",
    "print(x2, x2.size())\n",
    "print(x3, x3.size())\n",
    "print(x4, x4.size())\n",
    "print(x5, x5.size())\n",
    "print(x6, x6.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 1],\n",
      "         [2, 1, 2]],\n",
      "\n",
      "        [[3, 0, 3],\n",
      "         [0, 3, 0]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[1, 2, 1],\n",
      "         [2, 1, 2]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[1, 2],\n",
      "         [2, 1]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [0, 3]]]) torch.Size([2, 2, 2])\n",
      "tensor([[[1, 2, 1],\n",
      "         [3, 0, 3]],\n",
      "\n",
      "        [[2, 1, 2],\n",
      "         [0, 3, 0]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[1, 3],\n",
      "         [2, 0]],\n",
      "\n",
      "        [[2, 0],\n",
      "         [1, 3]],\n",
      "\n",
      "        [[1, 3],\n",
      "         [2, 0]]]) torch.Size([3, 2, 2])\n",
      "tensor([[[1, 2],\n",
      "         [2, 1],\n",
      "         [1, 2]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [0, 3],\n",
      "         [3, 0]]]) torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ [ [ 1, 2, 1 ], [ 2, 1, 2 ] ],\n",
    "                   [ [ 3, 0, 3 ], [ 0, 3, 0 ] ] ])\n",
    "\n",
    "x1 = x[0:1, :, :]\n",
    "x2 = x[:, :, 0:2]\n",
    "x3 = x.transpose(0, 1)\n",
    "x4 = x.transpose(0, 2)\n",
    "x5 = x.transpose(1, 2)\n",
    "\n",
    "print(x, x.size())\n",
    "print(x1, x1.size())\n",
    "print(x2, x2.size())\n",
    "print(x3, x3.size())\n",
    "print(x4, x4.size())\n",
    "print(x5, x5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch offers simple interfaces to standard image data-bases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]]) torch.Size([4, 1])\n",
      "B = tensor([[ 5., -5.,  5., -5.,  5.]]) torch.Size([1, 5])\n",
      "--------------------\n",
      "C = \n",
      " tensor([[ 6., -4.,  6., -4.,  6.],\n",
      "        [ 7., -3.,  7., -3.,  7.],\n",
      "        [ 8., -2.,  8., -2.,  8.],\n",
      "        [ 9., -1.,  9., -1.,  9.]]) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting automagically expands dimensions by replicating coefficients,\n",
    "# when it is necessary to perform operations that are “intuitively reasonable”.\n",
    "\n",
    "# Precisely, broadcasting proceeds as follows:\n",
    "# 1. If one of the tensors has fewer dimensions than the other, it is reshaped by\n",
    "# adding as many dimensions of size 1 as necessary in the front; then\n",
    "# 2. for every dimension mismatch, if one of the two tensors is of size one, it\n",
    "# is expanded along this axis by replicating coefficients.\n",
    "# If there is a tensor size mismatch for one of the dimension and neither of them\n",
    "# is one, the operation fails.\n",
    "\n",
    "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
    "C = A + B\n",
    "\n",
    "\n",
    "print(\"A = \\n\", A, A.size())\n",
    "print(\"B =\", B, B.size())\n",
    "print(\"-\"*20)\n",
    "print(\"C = \\n\", C, C.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\c10/core/TensorImpl.h:806: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 1024])\n",
      "-----\n",
      "torch.Size([3, 1024])\n",
      "torch.Size([100, 1024])\n",
      "torch.Size([100, 3])\n",
      "--------------------\n",
      "torch.Size([100, 1024, 3])\n",
      "--------------------\n",
      "torch.Size([100, 3072])\n",
      "('n', 'i')\n"
     ]
    }
   ],
   "source": [
    "# To deal with complex operations, PyTorch provides a dimension naming mechanism:\n",
    "seq = torch.empty(100, 3, 1024, names = [ 'n', 'c', 't' ]).normal_()\n",
    "\n",
    "mean_1 = seq.mean('n')\n",
    "mean_2 = seq.mean('c')\n",
    "mean_3 = seq.mean('t')\n",
    "\n",
    "print(seq.size())\n",
    "print(\"-\"*5)\n",
    "print(mean_1.size())\n",
    "print(mean_2.size())\n",
    "print(mean_3.size())\n",
    "print(\"-\"*20)\n",
    "\n",
    "time_first = seq.align_to('n', 't', 'c')\n",
    "print(time_first.size())\n",
    "print(\"-\"*20)\n",
    "\n",
    "array = seq.flatten([ 'c', 't' ], 'i')\n",
    "print(array.size())\n",
    "print(array.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Tensor Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-6-tensor-internals.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24b60b1c0f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-6-tensor-internals.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      " 0.0\n",
      "[torch.FloatStorage of size 8]\n",
      "----------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# A tensor is a view of a [part of a] storage, which is a low-level 1d vector.\n",
    "x = torch.zeros(2, 4)\n",
    "print(x.storage())\n",
    "print(\"-\"*10)\n",
    "\n",
    "q = x.storage()\n",
    "q[4] = 1.0\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[1., 0.],\n",
      "         [0., 0.]]])\n",
      "----------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [1., 0., 7., 0.]])\n",
      "----------\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# Multiple tensors can share the same storage. It happens when using operations\n",
    "# such as view(), expand() or transpose().\n",
    "\n",
    "y = x.view(2, 2, 2)\n",
    "print(y)\n",
    "print(\"-\"*10)\n",
    "\n",
    "y[1, 1, 0] = 7.0\n",
    "print(x)\n",
    "print(\"-\"*10)\n",
    "\n",
    "y.narrow(0, 1, 1).fill_(3.0)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 9., 10.],\n",
      "        [13., 14.]])\n"
     ]
    }
   ],
   "source": [
    "# The first coefficient of a tensor is the one at storage_offset() in storage().\n",
    "# Incrementing index k by 1 move by stride(k) elements in the storage.\n",
    "\n",
    "q = torch.arange(0, 20).storage().float()\n",
    "\n",
    "x = torch.empty(0).set_(q, storage_offset = 5, size = (3, 2), stride = (4, 1))\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "tensor([[2., 3., 4.],\n",
      "        [2., 3., 4.],\n",
      "        [2., 3., 4.]])\n",
      "tensor([[2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.]])\n",
      "----------\n",
      "(100, 1)\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "# We can explicitly create different “views” of the same storage\n",
    "n = torch.linspace(1, 4, 4)\n",
    "print(n)\n",
    "\n",
    "n1 = torch.tensor(0.).set_(n.storage(), 1, (3, 3), (0, 1))\n",
    "print(n1)\n",
    "\n",
    "n2 = torch.tensor(0.).set_(n.storage(), 1, (2, 4), (1, 0))\n",
    "print(n2)\n",
    "print(\"-\"*10)\n",
    "\n",
    "# This is in particular how transpositions and broadcasting are implemented.\n",
    "x = torch.empty(100, 100)\n",
    "print(x.stride())\n",
    "\n",
    "y = x.t()\n",
    "print(y.stride())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1a4feefc0c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# The function reshape() combines view() and contiguous().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# This organization explains the following (maybe surprising) error\n",
    "\n",
    "x = torch.empty(100, 100)\n",
    "x.t().view(-1)\n",
    "\n",
    "# The function reshape() combines view() and contiguous().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Tensor Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-4-2-autograd.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x24b60b14940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-4-2-autograd.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptually, the forward pass is a standard tensor computation, and the DAG\n",
    "of tensor operations is required only to compute derivatives.\n",
    "\n",
    "__When executing tensor operations, PyTorch can automatically construct\n",
    "on-the-fly the graph of operations to compute the gradient of any quantity\n",
    "with respect to any tensor involved.__\n",
    "\n",
    "This “autograd” mechanism (Paszke et al., 2017) has two main benefits:\n",
    "\n",
    "- Simpler syntax: one just needs to write the forward pass as a standard sequence of Python operations,\n",
    "- Greater flexibility: since the graph is not static, the forward pass can be dynamically modulated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: False\n",
      "x+y: False\n",
      "x+z: True\n"
     ]
    }
   ],
   "source": [
    "# A Tensor has a Boolean field requires_grad, set to False by default, \n",
    "# which states if PyTorch should build the graph of operations so that gradients with respect to it can be computed.\n",
    "\n",
    "# The result of a tensorial operation has this flag to True if any of its operand has it to True.\n",
    "\n",
    "x = torch.tensor([ 1., 2. ])\n",
    "y = torch.tensor([ 4., 5. ])\n",
    "z = torch.tensor([ 7., 3. ])\n",
    "\n",
    "print(\"x:\", x.requires_grad)\n",
    "print(\"x+y:\", (x + y).requires_grad)\n",
    "\n",
    "z.requires_grad = True\n",
    "print(\"x+z:\", (x + z).requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only Tensors of floating point dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-92b741e7f7b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only Tensors of floating point dtype can require gradients"
     ]
    }
   ],
   "source": [
    "# Only floating point type tensors can have their gradient computed.\n",
    "\n",
    "x = torch.tensor([1., 10.])\n",
    "x.requires_grad = True\n",
    "\n",
    "x = torch.tensor([1, 10])\n",
    "x.requires_grad = True\n",
    "\n",
    "# The method requires_grad_(value = True) set requires_grad to value, which is True by default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.grad(outputs, inputs) computes and returns the gradient\n",
    "# of outputs with respect to inputs.\n",
    "\n",
    "t = torch.tensor([1., 2., 4.]).requires_grad_()\n",
    "u = torch.tensor([10., 20.]).requires_grad_()\n",
    "a = t.pow(2).sum() + u.log().sum()\n",
    ">>> torch.autograd.grad(a, (t, u))\n",
    "(tensor([2., 4., 8.]), tensor([0.1000, 0.0500]))\n",
    "inputs can be a single tensor, but the result is still a [one element] tuple.\n",
    "If outputs is a tuple, the result is the sum of the gradients of its elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The function Tensor.backward() accumulates gradients in the grad fields of\n",
    "tensors which are not results of operations, the “leaves” in the autograd graph.\n",
    ">>> x = torch.tensor([ -3., 2., 5. ]).requires_grad_()\n",
    ">>> u = x.pow(3).sum()\n",
    ">>> x.grad\n",
    ">>> u.backward()\n",
    ">>> x.grad\n",
    "tensor([27., 12., 75.])\n",
    "This function is an alternative to torch.autograd.grad(...) and standard for\n",
    "training models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
