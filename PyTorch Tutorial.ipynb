{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial\n",
    "\n",
    "PyTorch is a Python library built on top of Torch’s THNN computational\n",
    "backend.\n",
    "\n",
    "Its main features are:\n",
    "\n",
    "- Efficient tensor operations on CPU/GPU,\n",
    "- automatic on-the-fly differentiation (autograd),\n",
    "- optimizers,\n",
    "- data I/O.\n",
    "\n",
    "“Efficient tensor operations” encompass both standard linear algebra and, as we will see later, deep-learning specific operations (convolution, pooling, etc.)\n",
    "\n",
    "A key specificity of PyTorch is the central role of autograd to compute\n",
    "derivatives of anything!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1 - Tensor Basics and Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-4-tensors-and-linear-regression.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22e5013a518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-4-tensors-and-linear-regression.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1112e-38, 9.5511e-39, 1.0102e-38, 1.0286e-38, 1.0194e-38],\n",
      "        [9.6429e-39, 9.2755e-39, 9.1837e-39, 9.3674e-39, 1.0745e-38]])\n",
      "torch.Size([2, 5])\n",
      "2 - 5\n",
      "tensor([[1.1250, 1.1250, 1.1250, 1.1250, 1.1250],\n",
      "        [1.1250, 1.1250, 1.1250, 1.1250, 1.1250]])\n",
      "tensor(1.1250)\n",
      "tensor(0.)\n",
      "tensor(11.2500)\n",
      "11.25\n"
     ]
    }
   ],
   "source": [
    "# In-place operations are suffixed with an underscore, and a 0d tensor can be\n",
    "# converted back to a Python scalar with item().\n",
    "\n",
    "x = torch.empty(2, 5)\n",
    "print(x)\n",
    "\n",
    "print(x.size())\n",
    "print(str(x.size()[0]) + \" - \" + str(x.size()[1]))\n",
    "\n",
    "x.fill_(1.125)\n",
    "print(x)\n",
    "\n",
    "print(x.mean())\n",
    "print(x.std())\n",
    "print(x.sum())\n",
    "print(x.sum().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11., 12., 13.],\n",
      "        [21., 22., 23.]])\n",
      "tensor(23.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[11. , 12. ,13.], [21., 22., 23.]])\n",
    "\n",
    "print(x)\n",
    "print(x[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21., 41., 61.])\n",
      "tensor([110., 420., 930.])\n",
      "tensor([100., 400., 900.])\n",
      "tensor([90., 40., 10.])\n",
      "tensor([90., 40., 10.])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch provides operators for component-wise and vector/matrix operations.\n",
    "x = torch.tensor([10., 20., 30.])\n",
    "y = torch.tensor([11., 21., 31.])\n",
    "\n",
    "m = torch.tensor([[0., 0., 3.], [0., 2., 0.], [1., 0., 0.]])\n",
    "\n",
    "z1 = x + y\n",
    "z2 = x * y\n",
    "z3 = x**2\n",
    "\n",
    "z4 = m.mv(x)\n",
    "z5 = m @ x\n",
    "\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "print(z4)\n",
    "print(z5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 3., 6., 1.],\n",
      "        [5., 4., 8., 4.]])\n",
      "tensor([4., 3., 6., 1.])\n",
      "tensor([4., 3., 6., 1.])\n",
      "tensor([4., 5.])\n"
     ]
    }
   ],
   "source": [
    "# And as in numpy, the : symbol defines a range of values for an index and allows\n",
    "# to slice tensors.\n",
    "\n",
    "x = torch.empty(2, 4).random_(10)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(x[0])\n",
    "print(x[0,:])\n",
    "\n",
    "print(x[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3149,  0.8815, -0.2879])\n",
      "tensor([[ 1.4682, -0.0593,  2.5764],\n",
      "        [ 0.7981, -2.9244,  0.4901],\n",
      "        [-0.7535, -1.8658, -0.0705]])\n",
      "tensor([[ 0.7705],\n",
      "        [-0.1448],\n",
      "        [-0.3202]])\n",
      "tensor([[ 0.3149],\n",
      "        [ 0.8815],\n",
      "        [-0.2879]])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch provides interfacing to standard linear operations, such as linear system\n",
    "# solving or Eigen-decomposition.\n",
    "\n",
    "y = torch.empty(3).normal_()\n",
    "m = torch.empty(3, 3).normal_()\n",
    "print(y)\n",
    "print(m)\n",
    "\n",
    "q, _ = torch.lstsq(y,m)\n",
    "s = torch.mm(m,q)\n",
    "print(q)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2 - High Dimension Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-5-high-dimension-tensors.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22e50166d30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-5-high-dimension-tensors.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor can be of several types:\n",
    "- torch.float16, torch.float32, torch.float64,\n",
    "- torch.uint8,\n",
    "- torch.int8, torch.int16, torch.int32, torch.int64\n",
    "\n",
    "and can be located either in the CPU’s or in a GPU’s memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 cpu\n",
      "torch.int64 cpu\n",
      "torch.int64 cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1,3)\n",
    "print(x.dtype, x.device)\n",
    "\n",
    "x = x.long()\n",
    "print(x.dtype, x.device)\n",
    "\n",
    "x = x.to('cuda')\n",
    "print(x.dtype, x.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some examples from the vast library of tensor operations:\n",
    "#### Creation\n",
    "- torch.empty(*size, ...)\n",
    "- torch.zeros(*size, ...)\n",
    "- torch.full(size, value, ...)\n",
    "- torch.tensor(sequence, ...)\n",
    "- torch.eye(n, ...)\n",
    "- torch.from_numpy(ndarray)\n",
    "\n",
    "#### Indexing, Slicing, Joining, Mutating\n",
    "- torch.Tensor.view(*size)\n",
    "- torch.cat(inputs, dimension=0)\n",
    "- torch.chunk(tensor, nb_chunks, dim=0)[source]\n",
    "- torch.split(tensor, split_size, dim=0)[source]\n",
    "- torch.index_select(input, dim, index, out=None)\n",
    "- torch.t(input, out=None)\n",
    "- torch.transpose(input, dim0, dim1, out=None)\n",
    "\n",
    "#### Filling\n",
    "- Tensor.fill_(value)\n",
    "- torch.bernoulli_(proba)\n",
    "- torch.normal_([mu, [std]])\n",
    "\n",
    "#### Pointwise math\n",
    "- torch.abs(input, out=None)\n",
    "- torch.add()\n",
    "- torch.cos(input, out=None)\n",
    "- torch.sigmoid(input, out=None)\n",
    "- (+ many operators)\n",
    "\n",
    "#### Math reduction\n",
    "- torch.dist(input, other, p=2, out=None)\n",
    "- torch.mean()\n",
    "- torch.norm()\n",
    "- torch.std()\n",
    "- torch.sum()\n",
    "\n",
    "#### BLAS and LAPACK Operations\n",
    "- torch.eig(a, eigenvectors=False, out=None)\n",
    "- torch.lstsq(B, A, out=None)\n",
    "- torch.inverse(input, out=None)\n",
    "- torch.mm(mat1, mat2, out=None)\n",
    "- torch.mv(mat, vec, out=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 0],\n",
      "        [2, 4, 6]]) torch.Size([2, 3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [0, 6]]) torch.Size([3, 2])\n",
      "tensor([1, 3, 0, 2, 4, 6]) torch.Size([6])\n",
      "tensor([[1, 3],\n",
      "        [0, 2],\n",
      "        [4, 6]]) torch.Size([3, 2])\n",
      "tensor([[3, 0],\n",
      "        [4, 6]]) torch.Size([2, 2])\n",
      "tensor([[[1, 3, 0],\n",
      "         [2, 4, 6]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[1, 3, 0],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 0],\n",
      "         [2, 4, 6]],\n",
      "\n",
      "        [[1, 3, 0],\n",
      "         [2, 4, 6]]]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ [1, 3, 0], [2, 4, 6] ])\n",
    "\n",
    "x1 = x.t()\n",
    "x2 = x.view(-1)\n",
    "x3 = x.view(3, -1)\n",
    "x4 = x[:, 1:3]\n",
    "x5 = x.view(1, 2, 3)\n",
    "x6 = x.view(1, 2, 3).expand(3, 2, 3)\n",
    "\n",
    "print(x, x.size())\n",
    "print(x1, x1.size())\n",
    "print(x2, x2.size())\n",
    "print(x3, x3.size())\n",
    "print(x4, x4.size())\n",
    "print(x5, x5.size())\n",
    "print(x6, x6.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 1],\n",
      "         [2, 1, 2]],\n",
      "\n",
      "        [[3, 0, 3],\n",
      "         [0, 3, 0]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[1, 2, 1],\n",
      "         [2, 1, 2]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[1, 2],\n",
      "         [2, 1]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [0, 3]]]) torch.Size([2, 2, 2])\n",
      "tensor([[[1, 2, 1],\n",
      "         [3, 0, 3]],\n",
      "\n",
      "        [[2, 1, 2],\n",
      "         [0, 3, 0]]]) torch.Size([2, 2, 3])\n",
      "tensor([[[1, 3],\n",
      "         [2, 0]],\n",
      "\n",
      "        [[2, 0],\n",
      "         [1, 3]],\n",
      "\n",
      "        [[1, 3],\n",
      "         [2, 0]]]) torch.Size([3, 2, 2])\n",
      "tensor([[[1, 2],\n",
      "         [2, 1],\n",
      "         [1, 2]],\n",
      "\n",
      "        [[3, 0],\n",
      "         [0, 3],\n",
      "         [3, 0]]]) torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([ [ [ 1, 2, 1 ], [ 2, 1, 2 ] ],\n",
    "                   [ [ 3, 0, 3 ], [ 0, 3, 0 ] ] ])\n",
    "\n",
    "x1 = x[0:1, :, :]\n",
    "x2 = x[:, :, 0:2]\n",
    "x3 = x.transpose(0, 1)\n",
    "x4 = x.transpose(0, 2)\n",
    "x5 = x.transpose(1, 2)\n",
    "\n",
    "print(x, x.size())\n",
    "print(x1, x1.size())\n",
    "print(x2, x2.size())\n",
    "print(x3, x3.size())\n",
    "print(x4, x4.size())\n",
    "print(x5, x5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch offers simple interfaces to standard image data-bases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]]) torch.Size([4, 1])\n",
      "B = tensor([[ 5., -5.,  5., -5.,  5.]]) torch.Size([1, 5])\n",
      "--------------------\n",
      "C = \n",
      " tensor([[ 6., -4.,  6., -4.,  6.],\n",
      "        [ 7., -3.,  7., -3.,  7.],\n",
      "        [ 8., -2.,  8., -2.,  8.],\n",
      "        [ 9., -1.,  9., -1.,  9.]]) torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting automagically expands dimensions by replicating coefficients,\n",
    "# when it is necessary to perform operations that are “intuitively reasonable”.\n",
    "\n",
    "# Precisely, broadcasting proceeds as follows:\n",
    "# 1. If one of the tensors has fewer dimensions than the other, it is reshaped by\n",
    "# adding as many dimensions of size 1 as necessary in the front; then\n",
    "# 2. for every dimension mismatch, if one of the two tensors is of size one, it\n",
    "# is expanded along this axis by replicating coefficients.\n",
    "# If there is a tensor size mismatch for one of the dimension and neither of them\n",
    "# is one, the operation fails.\n",
    "\n",
    "A = torch.tensor([[1.], [2.], [3.], [4.]])\n",
    "B = torch.tensor([[5., -5., 5., -5., 5.]])\n",
    "C = A + B\n",
    "\n",
    "\n",
    "print(\"A = \\n\", A, A.size())\n",
    "print(\"B =\", B, B.size())\n",
    "print(\"-\"*20)\n",
    "print(\"C = \\n\", C, C.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 1024])\n",
      "-----\n",
      "torch.Size([3, 1024])\n",
      "torch.Size([100, 1024])\n",
      "torch.Size([100, 3])\n",
      "--------------------\n",
      "torch.Size([100, 1024, 3])\n",
      "--------------------\n",
      "torch.Size([100, 3072])\n",
      "('n', 'i')\n"
     ]
    }
   ],
   "source": [
    "# To deal with complex operations, PyTorch provides a dimension naming mechanism:\n",
    "seq = torch.empty(100, 3, 1024, names = [ 'n', 'c', 't' ]).normal_()\n",
    "\n",
    "mean_1 = seq.mean('n')\n",
    "mean_2 = seq.mean('c')\n",
    "mean_3 = seq.mean('t')\n",
    "\n",
    "print(seq.size())\n",
    "print(\"-\"*5)\n",
    "print(mean_1.size())\n",
    "print(mean_2.size())\n",
    "print(mean_3.size())\n",
    "print(\"-\"*20)\n",
    "\n",
    "time_first = seq.align_to('n', 't', 'c')\n",
    "print(time_first.size())\n",
    "print(\"-\"*20)\n",
    "\n",
    "array = seq.flatten([ 'c', 't' ], 'i')\n",
    "print(array.size())\n",
    "print(array.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Tensor Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"https://fleuret.org/ee559/materials/ee559-slides-1-6-tensor-internals.pdf#view=Fit\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22e50166cf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"https://fleuret.org/ee559/materials/ee559-slides-1-6-tensor-internals.pdf#view=Fit\", height=500, width=\"100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
